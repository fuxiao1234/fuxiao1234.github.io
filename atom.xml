<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hexo</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2024-06-12T07:31:52.830Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>John Doe</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>《Spark HA &amp; Yarn 配置》</title>
    <link href="http://example.com/2024/06/12/%E3%80%8ASpark-HA-Yarn-%E9%85%8D%E7%BD%AE%E3%80%8B/"/>
    <id>http://example.com/2024/06/12/%E3%80%8ASpark-HA-Yarn-%E9%85%8D%E7%BD%AE%E3%80%8B/</id>
    <published>2024-06-12T07:29:43.000Z</published>
    <updated>2024-06-12T07:31:52.830Z</updated>
    
    <content type="html"><![CDATA[<h1 id="《Spark-HA-Yarn-配置》"><a href="#《Spark-HA-Yarn-配置》" class="headerlink" title="《Spark HA &amp; Yarn 配置》"></a>《Spark HA &amp; Yarn 配置》</h1><p>Spark HA &amp; Yarn 配置<br>Apache Spark 是一个用于大规模数据处理的快速、通用引擎。在分布式环境中运行 Spark 时，高可用性和资源管理是两项关键功能。Spark 提供了多种部署模式，其中高可用性（HA）模式和与 YARN（Yet Another Resource Negotiator）的集成特别重要。本文将介绍如何在 Spark 中配置这两种模式。</p><h2 id="1-Spark-高可用性（HA）配置"><a href="#1-Spark-高可用性（HA）配置" class="headerlink" title="1. Spark 高可用性（HA）配置"></a>1. Spark 高可用性（HA）配置</h2><p>在 Spark 中，高可用性（HA）模式允许 Master 节点在发生故障时自动切换到备用节点，从而确保集群的连续性和可用性。Spark Standalone 模式支持基于 Apache ZooKeeper 的 HA 配置。</p><h3 id="1-1-配置-ZooKeeper"><a href="#1-1-配置-ZooKeeper" class="headerlink" title="1.1 配置 ZooKeeper"></a>1.1 配置 ZooKeeper</h3><p>在配置 Spark HA 之前，你需要先安装并配置 ZooKeeper 集群。ZooKeeper 提供了分布式协调服务，用于维护配置信息、命名、提供分布式同步和提供组服务。</p><h3 id="1-2-配置-Spark-Master"><a href="#1-2-配置-Spark-Master" class="headerlink" title="1.2 配置 Spark Master"></a>1.2 配置 Spark Master</h3><p>在 Spark 的 conf 目录下，编辑 spark-env.sh 文件，为 Spark Master 设置 ZooKeeper 的连接字符串。你需要添加类似以下内容的行：</p><p>bash<br>export SPARK_DAEMON_JAVA_OPTS&#x3D;”-Dspark.deploy.zookeeper.url&#x3D;zk:&#x2F;&#x2F;zookeeper1:2181,zookeeper2:2181,zookeeper3:2181 -Dspark.deploy.zookeeper.dir&#x3D;&#x2F;spark”<br>这里 zk:&#x2F;&#x2F;zookeeper1:2181,zookeeper2:2181,zookeeper3:2181 是你的 ZooKeeper 集群的连接字符串，&#x2F;spark 是 Spark 在 ZooKeeper 中使用的目录。</p><h3 id="1-3-启动-Spark-Master"><a href="#1-3-启动-Spark-Master" class="headerlink" title="1.3 启动 Spark Master"></a>1.3 启动 Spark Master</h3><p>在配置完成后，你可以启动多个 Spark Master 实例，并使用相同的 ZooKeeper 配置。Spark 将使用 ZooKeeper 来协调 Master 之间的状态，并在主 Master 节点故障时自动切换到备用 Master。</p><h3 id="4-配置-Worker-节点"><a href="#4-配置-Worker-节点" class="headerlink" title=".4 配置 Worker 节点"></a>.4 配置 Worker 节点</h3><p>Worker 节点也需要知道 Master 的 ZooKeeper 配置，但它们通常不需要直接编辑配置文件。相反，Worker 节点在启动时通过 –master 参数连接到 Master 的 ZooKeeper URL。</p><h2 id="2-Spark-与-YARN-集成配置"><a href="#2-Spark-与-YARN-集成配置" class="headerlink" title="2. Spark 与 YARN 集成配置"></a>2. Spark 与 YARN 集成配置</h2><p>YARN（Yet Another Resource Negotiator）是 Hadoop 2.x 中的一个资源管理器，用于管理集群中的资源（如内存和 CPU）。Spark 可以通过 YARN 集群管理器来部署应用程序，从而利用 YARN 的资源管理和调度功能。</p><h3 id="2-1-配置-Spark"><a href="#2-1-配置-Spark" class="headerlink" title="2.1 配置 Spark"></a>2.1 配置 Spark</h3><p>在 Spark 的 conf 目录下，编辑 spark-defaults.conf 文件（如果不存在则创建），添加以下配置来启用 YARN 支持：</p><p>spark.master yarn<br>spark.executor.memory 1g<br>spark.executor.cores 1<br>spark.driver.memory 1g<br>这里，spark.master 设置为 yarn 以启用 YARN 模式，spark.executor.memory 和 spark.executor.cores 分别设置每个 Executor 的内存和核心数，spark.driver.memory 设置 Driver 程序的内存。</p><h3 id="2-2-配置-YARN"><a href="#2-2-配置-YARN" class="headerlink" title="2.2 配置 YARN"></a>2.2 配置 YARN</h3><p>YARN 的配置主要在 Hadoop 的配置文件中进行，如 yarn-site.xml 和 core-site.xml。你需要确保 YARN 集群已正确配置，并且 Hadoop 的配置文件对 Spark 可见。</p><h3 id="2-3-提交-Spark-应用程序到-YARN"><a href="#2-3-提交-Spark-应用程序到-YARN" class="headerlink" title="2.3 提交 Spark 应用程序到 YARN"></a>2.3 提交 Spark 应用程序到 YARN</h3><p>使用 spark-submit 命令提交 Spark 应用程序到 YARN 集群：</p><p>bash<br>.&#x2F;bin&#x2F;spark-submit \<br>  –class com.example.Main \<br>  –master yarn \<br>  –deploy-mode cluster \<br>  &#x2F;path&#x2F;to&#x2F;your-app.jar \<br>  [application-arguments]<br>在这里，–master yarn 指定使用 YARN 作为集群管理器，–deploy-mode cluster 指定在 YARN 集群上运行 Driver 程序（而不是在客户端上）。</p><h2 id="3-总结"><a href="#3-总结" class="headerlink" title="3. 总结"></a>3. 总结</h2><p>通过配置 Spark 的高可用性（HA）模式和与 YARN 的集成，你可以确保 Spark 集群的连续性和可用性，并有效地利用集群资源。HA 模式通过 ZooKeeper 提供了 Master 节点之间的协调，而 YARN 模式则允许 Spark 利用 Hadoop YARN 集群的资源管理和调度功能。这些配置可以根据你的具体需求进行调整和优化。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;《Spark-HA-Yarn-配置》&quot;&gt;&lt;a href=&quot;#《Spark-HA-Yarn-配置》&quot; class=&quot;headerlink&quot; title=&quot;《Spark HA &amp;amp; Yarn 配置》&quot;&gt;&lt;/a&gt;《Spark HA &amp;amp; Yarn 配置》&lt;/</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>《Spark local&amp; stand-alone 配置》</title>
    <link href="http://example.com/2024/06/12/%E3%80%8ASpark-local-stand-alone-%E9%85%8D%E7%BD%AE%E3%80%8B/"/>
    <id>http://example.com/2024/06/12/%E3%80%8ASpark-local-stand-alone-%E9%85%8D%E7%BD%AE%E3%80%8B/</id>
    <published>2024-06-12T07:22:45.000Z</published>
    <updated>2024-06-12T07:27:21.065Z</updated>
    
    <content type="html"><![CDATA[<h1 id="《Spark-local-stand-alone-配置》"><a href="#《Spark-local-stand-alone-配置》" class="headerlink" title="《Spark local&amp; stand-alone 配置》"></a>《Spark local&amp; stand-alone 配置》</h1><h2 id="Spark-local-stand-alone-配置"><a href="#Spark-local-stand-alone-配置" class="headerlink" title="Spark local &amp; stand-alone 配置"></a>Spark local &amp; stand-alone 配置</h2><p>Apache Spark 是一个快速、通用的大规模数据处理引擎，它提供了大数据处理的分布式计算能力。Spark 支持多种运行模式，其中 local 和 stand-alone 是最常见的两种模式。本文将介绍如何在本地和单机模式下配置和运行 Spark。</p><h2 id="1-Spark-local-模式"><a href="#1-Spark-local-模式" class="headerlink" title="1. Spark local 模式"></a>1. Spark local 模式</h2><p>Spark local 模式允许你在单台机器上运行 Spark 应用程序，主要用于开发和测试。在这种模式下，Spark 的所有组件（Driver、Executor）都运行在同一个 JVM 进程中。</p><h2 id="1-1-配置"><a href="#1-1-配置" class="headerlink" title="1.1 配置"></a>1.1 配置</h2><p>在大多数情况下，你不需要进行任何特殊的配置即可在 local 模式下运行 Spark。但是，你可以通过设置环境变量 SPARK_MASTER_URL 来指定 Spark 的主节点 URL，虽然对于 local 模式，这个 URL 通常被设置为 local 或 local[*]。</p><p>local：表示 Spark 将在单个线程上运行。<br>local[K]：表示 Spark 将在 K 个线程上运行。<br>local[*]：表示 Spark 将使用所有可用的核心来运行。</p><h2 id="1-2-运行"><a href="#1-2-运行" class="headerlink" title="1.2 运行"></a>1.2 运行</h2><p>你可以通过 spark-shell 或 spark-submit 来在 local 模式下运行 Spark 应用程序。例如：</p><p>bash<br> 使用所有可用的核心运行 spark-shell<br>.&#x2F;bin&#x2F;spark-shell –master local[*]  </p><p> 使用 spark-submit 提交一个 JAR 文件到 local 模式<br>.&#x2F;bin&#x2F;spark-submit –class com.example.Main –master local[*] &#x2F;path&#x2F;to&#x2F;your-app.jar<br>2. Spark stand-alone 模式<br>Spark stand-alone 模式（或称为 Spark 独立模式）允许你在一个集群中运行 Spark，而不需要依赖外部的资源管理器（如 Hadoop YARN 或 Apache Mesos）。在这种模式下，你需要启动一个 Spark Master 和多个 Spark Worker 节点。</p><h2 id="2-1-配置"><a href="#2-1-配置" class="headerlink" title="2.1 配置"></a>2.1 配置</h2><p>在 stand-alone 模式下，你需要配置 spark-env.sh 文件来设置 Master 和 Worker 的相关参数。这个文件通常位于 Spark 安装目录的 conf 文件夹下。</p><p>2.1.1 Spark Master 配置<br>在 spark-env.sh 文件中，设置 SPARK_MASTER_HOST 和 SPARK_MASTER_PORT 来指定 Master 的主机名和端口。例如：</p><p>bash<br>export SPARK_MASTER_HOST&#x3D;your-master-hostname<br>export SPARK_MASTER_PORT&#x3D;7077<br>2.1.2 Spark Worker 配置<br>在 spark-env.sh 文件中，设置 SPARK_WORKER_CORES、SPARK_WORKER_MEMORY 和 SPARK_WORKER_INSTANCES 来指定每个 Worker 的核心数、内存大小和 Worker 实例数。例如：</p><p>bash<br>export SPARK_WORKER_CORES&#x3D;2<br>export SPARK_WORKER_MEMORY&#x3D;4g<br>export SPARK_WORKER_INSTANCES&#x3D;2<br>2.1.3 其他配置<br>你还可以配置其他参数，如日志级别、Java 虚拟机选项等。这些配置通常也在 spark-env.sh 文件中进行。</p><h2 id="2-2-启动和停止"><a href="#2-2-启动和停止" class="headerlink" title="2.2 启动和停止"></a>2.2 启动和停止</h2><p>2.2.1 启动 Spark Master<br>在配置好 spark-env.sh 文件后，你可以通过以下命令启动 Spark Master：</p><p>bash<br>.&#x2F;sbin&#x2F;start-master.sh<br>2.2.2 启动 Spark Worker<br>你可以通过以下命令启动 Spark Worker，并指定 Master 的 URL（如果 Master 和 Worker 不在同一台机器上）：</p><p>bash<br>.&#x2F;sbin&#x2F;start-worker.sh spark:&#x2F;&#x2F;your-master-hostname:7077<br>2.2.3 停止 Spark 集群<br>你可以通过以下命令停止 Spark Master 和 Worker：</p><p>bash<br>.&#x2F;sbin&#x2F;stop-master.sh<br>.&#x2F;sbin&#x2F;stop-worker.sh</p><h2 id="2-3-运行"><a href="#2-3-运行" class="headerlink" title="2.3 运行"></a>2.3 运行</h2><p>在 stand-alone 模式下运行 Spark 应用程序与在 local 模式下类似，但你需要将 –master 参数设置为 Spark Master 的 URL。例如：</p><p>bash<br>.&#x2F;bin&#x2F;spark-submit –class com.example.Main –master spark:&#x2F;&#x2F;your-master-hostname:7077 &#x2F;path&#x2F;to&#x2F;your-app.jar</p><h2 id="3-总结"><a href="#3-总结" class="headerlink" title="3. 总结"></a>3. 总结</h2><p>Spark local 和 stand-alone 模式为开发和测试 Spark 应用程序提供了灵活的环境。local 模式允许你在单台机器上快速验证你的代码，而 stand-alone 模式则允许你在一个小型集群中模拟生产环境。通过合理配置和运行这些模式，你可以更好地理解和优化你的 Spark 应用程序。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;《Spark-local-stand-alone-配置》&quot;&gt;&lt;a href=&quot;#《Spark-local-stand-alone-配置》&quot; class=&quot;headerlink&quot; title=&quot;《Spark local&amp;amp; stand-alone 配置》&quot;&gt;&lt;</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>《Spark 基础环境配置》</title>
    <link href="http://example.com/2024/06/12/%E3%80%8ASpark-%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E3%80%8B/"/>
    <id>http://example.com/2024/06/12/%E3%80%8ASpark-%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E3%80%8B/</id>
    <published>2024-06-12T05:22:06.000Z</published>
    <updated>2024-06-12T07:17:33.848Z</updated>
    
    <content type="html"><![CDATA[<h1 id="《Spark-基础环境配置》"><a href="#《Spark-基础环境配置》" class="headerlink" title="《Spark 基础环境配置》"></a>《Spark 基础环境配置》</h1><p>##Spark 基础环境配置<br>在启动 Apache Spark 集群之前，确保已经搭建好了必要的基础环境，包括 JDK（Java Development Kit）、Hadoop 和 Zookeeper。这些组件为 Spark 提供了必要的运行环境、分布式文件系统和分布式协调服务。下面将详细介绍如何配置这些基础环境。</p><h2 id="1-JDK-配置"><a href="#1-JDK-配置" class="headerlink" title="1. JDK 配置"></a>1. JDK 配置</h2><p>Apache Spark 使用 Java 编写，因此需要先安装 JDK。确保你的系统已经安装了 JDK 8 或更高版本，因为 Spark 官方推荐使用这些版本。<br>安装 JDK<br>你可以从 Oracle 官网下载 JDK 安装包，并按照提示进行安装。安装完成后，配置 JDK 的环境变量，包括 JAVA_HOME、PATH 和 CLASSPATH。</p><p>JAVA_HOME：指向 JDK 安装目录，如 &#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;java-8-openjdk-amd64（Linux&#x2F;macOS）或 C:\Program Files\Java\jdk-版本号（Windows）。<br>PATH：添加 JDK 的 bin 目录到 PATH 中，以便在任意目录下都能使用 Java 命令。<br>CLASSPATH：通常不需要手动设置，但在某些情况下可能需要添加 JDK 的库目录。<br>2. Hadoop 配置<br>Hadoop 为 Spark 提供了分布式文件系统（HDFS）和 YARN（Yet Another Resource Negotiator）作为资源管理器。因此，需要先安装和配置 Hadoop。</p><p>安装 Hadoop<br>你可以从 Hadoop 官网下载 Hadoop 安装包，并按照官方文档进行安装和配置。安装完成后，需要配置 Hadoop 的环境变量，包括 HADOOP_HOME 和 PATH。</p><p>HADOOP_HOME：指向 Hadoop 安装目录。<br>PATH：添加 Hadoop 的 bin 和 sbin 目录到 PATH 中，以便在任意目录下都能使用 Hadoop 命令。<br>配置 Hadoop<br>Hadoop 的配置文件主要位于 etc&#x2F;hadoop&#x2F; 目录下。你需要根据你的集群环境修改这些配置文件，包括 core-site.xml、hdfs-site.xml、yarn-site.xml 和 mapred-site.xml（可能需要先重命名 mapred-site.xml.template）。</p><h2 id="3-Zookeeper-配置"><a href="#3-Zookeeper-配置" class="headerlink" title="3. Zookeeper 配置"></a>3. Zookeeper 配置</h2><p>Zookeeper 是一个分布式协调服务，用于维护配置信息、命名、提供分布式同步和提供组服务等。在 Spark 中，Zookeeper 通常用于 Spark Streaming 的 Kafka 集成等场景。</p><p>安装 Zookeeper<br>你可以从 Apache 官网下载 Zookeeper 安装包，并按照官方文档进行安装和配置。安装完成后，需要配置 Zookeeper 的环境变量，包括 ZOOKEEPER_HOME 和 PATH。</p><p>ZOOKEEPER_HOME：指向 Zookeeper 安装目录。<br>PATH：添加 Zookeeper 的 bin 目录到 PATH 中，以便在任意目录下都能使用 Zookeeper 命令。<br>配置 Zookeeper<br>Zookeeper 的配置文件主要位于 conf&#x2F; 目录下。你需要根据你的集群环境修改 zoo.cfg 文件，包括设置数据目录、日志目录、监听端口和服务器列表等。</p><h2 id="4-安装和配置-Spark"><a href="#4-安装和配置-Spark" class="headerlink" title="4. 安装和配置 Spark"></a>4. 安装和配置 Spark</h2><p>在 JDK、Hadoop 和 Zookeeper 配置完成后，你可以开始安装和配置 Spark。</p><p>下载 Spark<br>从 Apache Spark 官网下载适合你操作系统的预编译包。</p><p>解压 Spark<br>将下载的 Spark 压缩包解压到你选择的目录。</p><p>配置环境变量<br>将 Spark 的 bin 目录添加到你的 PATH 环境变量中，以便在终端中直接运行 Spark 命令。</p><p>配置 Spark<br>在 Spark 的 conf&#x2F; 目录下，你可以找到一些配置文件，如 spark-env.sh 和 spark-defaults.conf。你可以根据需要修改这些配置文件，设置 Spark 的运行环境、内存分配、日志级别等。</p><p>spark-env.sh：设置 Spark 运行时的环境变量，如 Java 路径、Spark 主目录、内存分配等。<br>spark-defaults.conf：设置 Spark 的默认配置参数，如 Master URL、Executor 内存等。</p><h2 id="5-验证配置"><a href="#5-验证配置" class="headerlink" title="5. 验证配置"></a>5. 验证配置</h2><p>在配置完成后，你可以通过运行一些简单的命令或示例代码来验证你的配置是否正确。例如，你可以启动 Spark Shell 并尝试读取 HDFS 上的文件，或者启动一个 Spark 应用程序并观察其在 YARN 上的运行情况。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;《Spark-基础环境配置》&quot;&gt;&lt;a href=&quot;#《Spark-基础环境配置》&quot; class=&quot;headerlink&quot; title=&quot;《Spark 基础环境配置》&quot;&gt;&lt;/a&gt;《Spark 基础环境配置》&lt;/h1&gt;&lt;p&gt;##Spark 基础环境配置&lt;br&gt;在启动 </summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://example.com/2024/06/11/hello-world/"/>
    <id>http://example.com/2024/06/11/hello-world/</id>
    <published>2024-06-11T13:04:12.962Z</published>
    <updated>2024-06-11T01:21:34.159Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot;&gt;documentation&lt;/a&gt; for</summary>
      
    
    
    
    
  </entry>
  
</feed>
